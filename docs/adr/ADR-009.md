# ADR-009: MCP Server Integration

**Decision:** Add MCP (Model Context Protocol) server support as a new crate `mkb-mcp` to expose vault queries, document retrieval, and context assembly to AI-native editors.

**Rationale:**
- MCP is the de facto standard for AI tool integration in 2025-2026, adopted by Anthropic, OpenAI, Google DeepMind, Microsoft, and thousands of developers
- AI-native editors (Claude Desktop, Cursor, Replit, Sourcegraph) use MCP to connect to data sources
- MKB needs to be accessible from where users actually work — IDEs and AI assistants, not just CLI
- MCP was donated to the Agentic AI Foundation under Linux Foundation in December 2025, ensuring long-term standardization
- Following proven patterns: Will Larson's library-mcp and Google's Conductor demonstrate successful MCP integrations

**Architecture:**

The MCP server will be a thin layer over existing query infrastructure:

```
AI Editor (Claude Desktop, Cursor, etc.)
    ↓ MCP Protocol
mkb-mcp Server (Rust)
    ↓ Internal APIs
mkb-query Engine + mkb-vault
```

**Resources to Expose:**

- `mkb://vault/{type}/{id}` — retrieve individual documents by type and ID
- `mkb://query/{mkql}` — execute MKQL queries, return matching documents
- `mkb://context/{topic}` — assemble optimized LLM context with token budget management
- `mkb://signals/{type}` — access AI-inferred signals (priority, sentiment, etc.)

**Tools to Expose:**

- `mkb_query(mkql: str, limit: int)` — execute MKQL queries
- `mkb_search(query: str, type: str, limit: int)` — full-text and semantic search
- `mkb_ingest(content: str, type: str, metadata: dict)` — add documents to vault
- `mkb_context(topic: str, max_tokens: int)` — assemble context for LLM consumption
- `mkb_signals(doc_id: str)` — retrieve AI-inferred signals for a document

**Implementation Timeline:**

- Phase 7 (future): After core functionality (Phases 1-6) is stable
- Priority: Before v1.0 release to ensure AI-native tooling compatibility
- SDKs available in Python, TypeScript, C#, Java — start with Rust SDK

**Trade-offs:**
- Additional crate in workspace increases maintenance surface
- Need to track MCP protocol version updates (currently at 2025-11-25 spec)
- Security consideration: MCP servers exposed to internet often lack authentication (Knostic research, July 2025) — must implement proper auth
- Positions MKB for AI-native ecosystem but adds complexity before core is proven

**Consequences:**
- Enables Claude Desktop and Cursor users to query their knowledge base directly from editor
- MKB becomes a first-class citizen in AI-native workflows
- Community can build additional MCP-based integrations
- Future-proofs MKB for the agentic AI ecosystem emerging in 2025-2026
